{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing Libraries\n",
        "!pip install pytube -q\n",
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVu5-MO7oHg4",
        "outputId": "d7406681-f569-42eb-96cc-88421772f585"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "import whisper\n",
        "\n",
        "# Function to download video and get transcriptions\n",
        "def get_transcriptions(url):\n",
        "    yt_video = YouTube(url)\n",
        "    stream = yt_video.streams.filter(only_audio=True)\n",
        "    stream = stream.first()\n",
        "    stream.download(filename=\"test.mp4\")\n",
        "\n",
        "    model = whisper.load_model('base')\n",
        "    output = model.transcribe(\"test.mp4\")\n",
        "    return output[\"text\"]"
      ],
      "metadata": {
        "id": "pKZugGWBoHWI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of 4 video URLs\n",
        "video_urls = [\"https://www.youtube.com/watch?v=lE-VKc2R9L4\",\"https://www.youtube.com/watch?v=P9EnUasQQbE\",\n",
        "              \"https://www.youtube.com/watch?v=Ca7B6v-Unec\",\"https://www.youtube.com/watch?v=U6os4i3lu1U\"]\n",
        "\n",
        "transcription = []  # list to store transcriptions\n",
        "\n",
        "# Loop through each video URL and get transcriptions\n",
        "for i, url in enumerate(video_urls):\n",
        "    transcriptions = get_transcriptions(url)\n",
        "    transcription.append(transcriptions)\n",
        "\n",
        "# Print the transcriptions list length\n",
        "print(len(transcription))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylFj9P1woHQN",
        "outputId": "913ed334-a05a-4bd8-ac9a-0091d9da3f4f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/usr/local/lib/python3.9/dist-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the long transcribe into short text\n",
        "\n",
        "sh_text = []\n",
        "\n",
        "for i in transcription:\n",
        "  if len(i) >= 300:\n",
        "    for j in range(0,len(i),300):\n",
        "      sh_text.append(i[j:j+300])\n",
        "  else:\n",
        "    sh_text.append(i)"
      ],
      "metadata": {
        "id": "OHQqISsOoHJ5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sh_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzMf9Z4AoG6-",
        "outputId": "aa7fb69c-c64d-4c66-e555-6a588b1b3a9a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0to-QXCQjsm"
      },
      "source": [
        "# Retrieval Enhanced Generative Question Answering with OpenAI\n",
        "\n",
        "#### Fixing LLMs that Hallucinate\n",
        "\n",
        "In this notebook we will learn how to query relevant contexts to our queries from Pinecone, and pass these to a generative OpenAI model to generate an answer backed by real data sources. Required installs for this notebook are:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VpMvHAYRQf9N"
      },
      "outputs": [],
      "source": [
        "!pip install -qU openai pinecone-client datasets tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "aEreHNxYkDbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa4af4c-0c36-4ef7-a97e-f21587d9ae99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7f0682b5f3b0> JSON: {\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-edit-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-code-search-code\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-babbage-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-davinci-edit-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-003\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-code-search-text\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-babbage-text-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-curie-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"whisper-1\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-babbage-code-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-ada-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-embedding-ada-002\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-internal\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-ada-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-instruct-beta\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-code-search-code\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-ada-text-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-ada-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-code-search-text\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-ada-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-instruct-beta\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-curie-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"code-search-ada-code-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-davinci-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"ada-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-curie-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-babbage-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-search-document\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-curie-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"babbage-search-query\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-babbage-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-davinci-doc-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-search-babbage-query-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"curie\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-similarity-davinci-001\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"text-davinci-002\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-3.5-turbo-0301\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"gpt-3.5-turbo\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    },\n",
              "    {\n",
              "      \"created\": null,\n",
              "      \"id\": \"davinci-similarity\",\n",
              "      \"object\": \"engine\",\n",
              "      \"owner\": \"openai-dev\",\n",
              "      \"permissions\": null,\n",
              "      \"ready\": true\n",
              "    }\n",
              "  ],\n",
              "  \"object\": \"list\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# get API key from top-right dropdown on OpenAI website\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "openai.Engine.list()  # check we have authenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seS2VDFz0BCI"
      },
      "source": [
        "For many questions *state-of-the-art (SOTA)* LLMs are more than capable of answering correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "9FEDn7LvkDYj",
        "outputId": "70af831b-82ec-4cd6-95ff-a04a2087d5e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Dell Alienware laptop is a great choice for gamers and power users. It offers powerful hardware, a sleek design, and a wide range of features. The laptop is well-built and offers excellent performance, making it a great choice for gaming and other intensive tasks. It also has a great battery life and a wide range of ports and connectivity options.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "query = \"How is Dell Alienware laptop?\"\n",
        "\n",
        "# now query text-davinci-003 WITHOUT context\n",
        "res = openai.Completion.create(\n",
        "    engine='text-davinci-003',\n",
        "    prompt=query,\n",
        "    temperature=0,\n",
        "    max_tokens=400,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "    stop=None\n",
        ")\n",
        "\n",
        "res['choices'][0]['text'].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfHwX1qSldhY"
      },
      "source": [
        "However, that isn't always the case. Let's first rewrite the above into a simple function so we're not rewriting this every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "SczFSfnjmNji"
      },
      "outputs": [],
      "source": [
        "def complete(prompt):\n",
        "    # query text-davinci-003\n",
        "    res = openai.Completion.create(\n",
        "        engine='text-davinci-003',\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=400,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None\n",
        "    )\n",
        "    return res['choices'][0]['text'].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC6csbA40UW3"
      },
      "source": [
        "Now let's ask a more specific question about training a specific type of transformer model called a *sentence-transformer*. The ideal answer we'd be looking for is _\"Multiple Negatives Ranking (MNR) loss\"_.\n",
        "\n",
        "Don't worry if this is a new term to you, it isn't required to understand what we're doing or demoing here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "H2fUC8BtxCt_",
        "outputId": "2a2f508a-dd27-4627-b3f8-323af764f60a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'If you only have pairs of related sentences, then the best training method to use for sentence transformers is the supervised learning approach. This approach involves providing the model with labeled data, such as pairs of related sentences, and then training the model to learn the relationships between the sentences. This approach is often used for tasks such as natural language inference, semantic similarity, and paraphrase identification.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "query = (\n",
        "    \"Which training method should I use for sentence transformers when \" +\n",
        "    \"I only have pairs of related sentences?\"\n",
        ")\n",
        "\n",
        "complete(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7ut_DNBwIk1"
      },
      "source": [
        "One of the common answers I get to this is:\n",
        "\n",
        "```\n",
        "The best training method to use for fine-tuning a pre-trained model with sentence transformers is the Masked Language Model (MLM) training. MLM training involves randomly masking some of the words in a sentence and then training the model to predict the masked words. This helps the model to learn the context of the sentence and better understand the relationships between words.\n",
        "```\n",
        "\n",
        "This answer seems pretty convincing right? Yet, it's wrong. MLM is typically used in the pretraining step of a transformer model but *cannot* be used to fine-tune a sentence-transformer, and has nothing to do with having _\"pairs of related sentences\"_.\n",
        "\n",
        "An alternative answer I recieve is about `supervised learning approach` being the most suitable. This is completely true, but it's not specific and doesn't answer the question.\n",
        "\n",
        "We have two options for enabling our LLM in understanding and correctly answering this question:\n",
        "\n",
        "1. We fine-tune the LLM on text data covering the topic mentioned, likely on articles and papers talking about sentence transformers, semantic search training methods, etc.\n",
        "\n",
        "2. We use **R**etrieval **A**ugmented **G**eneration (RAG), a technique that implements an information retrieval component to the generation process. Allowing us to retrieve relevant information and feed this information into the generation model as a *secondary* source of information.\n",
        "\n",
        "We will demonstrate option **2**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhWnLkHqmeWI"
      },
      "source": [
        "---\n",
        "\n",
        "## Building a Knowledge Base\n",
        "\n",
        "With open **2** the retrieval of relevant information requires an external _\"Knowledge Base\"_, a place where we can store and use to efficiently retrieve information. We can think of this as the external _long-term memory_ of our LLM.\n",
        "\n",
        "We will need to retrieve information that is semantically related to our queries, to do this we need to use _\"dense vector embeddings\"_. These can be thought of as numerical representations of the *meaning* behind our sentences.\n",
        "\n",
        "There are many options for creating these dense vectors, like open source [sentence transformers](https://pinecone.io/learn/nlp/) or OpenAI's [ada-002 model](https://youtu.be/ocxq84ocYi0). We will use OpenAI's offering in this example.\n",
        "\n",
        "We have already authenticated our OpenAI connection, to create an embedding we just do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EI2iYxq16or9"
      },
      "outputs": [],
      "source": [
        "embed_model = \"text-embedding-ada-002\"\n",
        "\n",
        "res = openai.Embedding.create(\n",
        "    input=[\n",
        "        \"Sample document text goes here\",\n",
        "        \"there will be several phrases in each batch\"\n",
        "    ], engine=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnHpGP5R60Fv"
      },
      "source": [
        "In the response `res` we will find a JSON-like object containing our new embeddings within the `'data'` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57smZFmz61tj",
        "outputId": "7d44992c-e0f7-4071-829f-354832157542"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['object', 'data', 'model', 'usage'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "res.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwSk-wiK62KO"
      },
      "source": [
        "Inside `'data'` we will find two records, one for each of the two sentences we just embedded. Each vector embedding contains `1536` dimensions (the output dimensionality of the `text-embedding-ada-002` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36D4ipOR63AW",
        "outputId": "d4541e99-a31c-42b4-ab59-7c2912908e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "len(res['data'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res['data'][0]['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "761_21X5dF3l",
        "outputId": "3a45fb7d-eeb4-41b4-f250-05a2417f5dc8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.0031135426834225655,\n",
              " 0.011766765266656876,\n",
              " -0.00509151816368103,\n",
              " -0.027159256860613823,\n",
              " -0.01633599027991295,\n",
              " 0.03237545117735863,\n",
              " -0.016160769388079643,\n",
              " -0.0010808103252202272,\n",
              " -0.02583836019039154,\n",
              " -0.006641550455242395,\n",
              " 0.02012345939874649,\n",
              " 0.016672953963279724,\n",
              " -0.009178885258734226,\n",
              " 0.02331787347793579,\n",
              " -0.010149340145289898,\n",
              " 0.013458321802318096,\n",
              " 0.02527226135134697,\n",
              " -0.016915567219257355,\n",
              " 0.012056553736329079,\n",
              " -0.01636294648051262,\n",
              " -0.004303023684769869,\n",
              " -0.006402306258678436,\n",
              " -0.00437378603965044,\n",
              " 0.020810864865779877,\n",
              " -0.010567175224423409,\n",
              " -0.003726816037669778,\n",
              " 0.013626803644001484,\n",
              " -0.02635054476559162,\n",
              " -0.0004172029148321599,\n",
              " -0.0021852082572877407,\n",
              " 0.00576881505548954,\n",
              " -0.01012912206351757,\n",
              " -0.02817014791071415,\n",
              " -0.01622816175222397,\n",
              " -0.004255848936736584,\n",
              " 0.007426674943417311,\n",
              " -0.002897885860875249,\n",
              " -0.031431954354047775,\n",
              " 0.023843536153435707,\n",
              " -0.03329199180006981,\n",
              " -0.0003548646636772901,\n",
              " 0.013087661936879158,\n",
              " 0.007123407907783985,\n",
              " -0.0056812041439116,\n",
              " 0.003057943657040596,\n",
              " -0.029814528301358223,\n",
              " 0.02621575817465782,\n",
              " -0.004663574509322643,\n",
              " 0.0066348109394311905,\n",
              " 0.017481666058301926,\n",
              " 0.027280563488602638,\n",
              " 0.015756413340568542,\n",
              " -0.02218567579984665,\n",
              " 0.00282038445584476,\n",
              " -0.006459590047597885,\n",
              " 0.00635850103572011,\n",
              " -0.016942523419857025,\n",
              " 0.020029108971357346,\n",
              " 0.0034606149420142174,\n",
              " -0.0034943113569170237,\n",
              " -0.0011305124498903751,\n",
              " 0.003568443236872554,\n",
              " -0.0026889685541391373,\n",
              " -0.012494605965912342,\n",
              " -0.018074721097946167,\n",
              " -0.03517898917198181,\n",
              " -0.031701523810625076,\n",
              " 0.007547982037067413,\n",
              " 0.00705601554363966,\n",
              " 0.005556527990847826,\n",
              " 0.02068955823779106,\n",
              " 0.010998488403856754,\n",
              " -0.011611761525273323,\n",
              " -0.01738731563091278,\n",
              " 0.006621332373470068,\n",
              " 0.01014260109513998,\n",
              " -0.012110468000173569,\n",
              " -0.012380038388073444,\n",
              " 0.00031506086816079915,\n",
              " -0.001085864845663309,\n",
              " 0.004619769286364317,\n",
              " -0.026660550385713577,\n",
              " -0.002372222952544689,\n",
              " 0.03202500939369202,\n",
              " 0.009044099599123001,\n",
              " 0.014125509187579155,\n",
              " 0.018182549625635147,\n",
              " 0.02900581620633602,\n",
              " -0.021066956222057343,\n",
              " -0.017346879467368126,\n",
              " -0.005933926906436682,\n",
              " 0.015891198068857193,\n",
              " -0.0043535684235394,\n",
              " 0.01700991578400135,\n",
              " -0.013235925696790218,\n",
              " 0.021983496844768524,\n",
              " -0.005388046149164438,\n",
              " 0.024355720728635788,\n",
              " 0.0038211659993976355,\n",
              " -0.0409478023648262,\n",
              " 0.008478001691401005,\n",
              " 0.00987302977591753,\n",
              " -0.012110468000173569,\n",
              " -0.010284125804901123,\n",
              " -0.03938429057598114,\n",
              " 0.0057519664987921715,\n",
              " 0.016268596053123474,\n",
              " -0.014772479422390461,\n",
              " 0.01609337516129017,\n",
              " 0.014381601475179195,\n",
              " -0.021484792232513428,\n",
              " 0.012615912593901157,\n",
              " -0.004602921195328236,\n",
              " -0.03318416327238083,\n",
              " 0.01420638058334589,\n",
              " 0.004626508802175522,\n",
              " -0.004407482221722603,\n",
              " -0.021956540644168854,\n",
              " 0.0011195611441507936,\n",
              " -0.0051690200343728065,\n",
              " -0.013276360929012299,\n",
              " 0.026121409609913826,\n",
              " 0.04003126174211502,\n",
              " -0.01644381880760193,\n",
              " 0.01395028829574585,\n",
              " 0.023695271462202072,\n",
              " -0.005111736245453358,\n",
              " -0.031890224665403366,\n",
              " 0.012723741121590137,\n",
              " -0.005903600249439478,\n",
              " 0.018074721097946167,\n",
              " 0.042457398027181625,\n",
              " 0.024180499836802483,\n",
              " 0.02055477164685726,\n",
              " -0.02822406217455864,\n",
              " 0.018789084628224373,\n",
              " -0.04550354927778244,\n",
              " 0.019139526411890984,\n",
              " -0.021902626380324364,\n",
              " -0.01746818609535694,\n",
              " 0.008889096789062023,\n",
              " 0.03490941599011421,\n",
              " -0.006193388719111681,\n",
              " -0.006314695812761784,\n",
              " 0.006934708449989557,\n",
              " 0.011113055981695652,\n",
              " 0.000630964117590338,\n",
              " -0.021080436185002327,\n",
              " 0.01086370274424553,\n",
              " -0.01384245976805687,\n",
              " 0.01086370274424553,\n",
              " 0.0023705381900072098,\n",
              " -0.00705601554363966,\n",
              " 0.012002639472484589,\n",
              " 0.0037672517355531454,\n",
              " 0.02624271623790264,\n",
              " 0.012474387884140015,\n",
              " -0.003844753373414278,\n",
              " -0.0113624082878232,\n",
              " -0.0204739011824131,\n",
              " 0.008134298026561737,\n",
              " 0.01450290810316801,\n",
              " 0.019382139667868614,\n",
              " -0.010122383013367653,\n",
              " 0.010432389564812183,\n",
              " 0.04140607267618179,\n",
              " 0.002699077595025301,\n",
              " -0.010701959952712059,\n",
              " 0.0003576024901121855,\n",
              " -0.0176838431507349,\n",
              " -0.024477027356624603,\n",
              " 0.016969481483101845,\n",
              " -0.04566529020667076,\n",
              " 0.00417160801589489,\n",
              " -0.03313025087118149,\n",
              " 0.02459833398461342,\n",
              " 0.014974657446146011,\n",
              " 0.015028571709990501,\n",
              " -0.009138450026512146,\n",
              " -0.023169608786702156,\n",
              " -0.019840409979224205,\n",
              " 0.008006252348423004,\n",
              " 0.011861114762723446,\n",
              " 0.037200767546892166,\n",
              " -0.036499883979558945,\n",
              " -0.003689750097692013,\n",
              " -0.015527277253568172,\n",
              " 0.00045026745647192,\n",
              " 0.0026283152401447296,\n",
              " 0.000650760717689991,\n",
              " 0.00801973044872284,\n",
              " 0.010479564778506756,\n",
              " 0.005034234374761581,\n",
              " -0.023573964834213257,\n",
              " -0.690963864326477,\n",
              " -0.021147828549146652,\n",
              " -0.003753773169592023,\n",
              " -0.011773504316806793,\n",
              " 0.025717053562402725,\n",
              " 0.02068955823779106,\n",
              " 0.01173980813473463,\n",
              " 0.01018303632736206,\n",
              " -0.010439128614962101,\n",
              " 0.014085073955357075,\n",
              " -0.023142652586102486,\n",
              " 0.0053240228444337845,\n",
              " -0.0109580522403121,\n",
              " -0.003015823196619749,\n",
              " -0.01749514415860176,\n",
              " -0.01888343319296837,\n",
              " 0.0001238340773852542,\n",
              " 0.0038009481504559517,\n",
              " -0.01915300451219082,\n",
              " 0.007891684770584106,\n",
              " 0.0001177266167360358,\n",
              " 0.013532453216612339,\n",
              " -0.02892494574189186,\n",
              " 0.013775067403912544,\n",
              " 0.01250134501606226,\n",
              " -0.0008836867054924369,\n",
              " 0.005010646767914295,\n",
              " -0.01638990454375744,\n",
              " 0.0029720179736614227,\n",
              " 0.02438267692923546,\n",
              " -0.037389468401670456,\n",
              " -0.01106588076800108,\n",
              " -0.005044343415647745,\n",
              " 0.02242828905582428,\n",
              " 0.053779371082782745,\n",
              " -0.00013826032227370888,\n",
              " -0.00014478899538516998,\n",
              " -0.0073255859315395355,\n",
              " 0.011247840709984303,\n",
              " 0.013235925696790218,\n",
              " -0.018317334353923798,\n",
              " -0.0174142736941576,\n",
              " 0.006051864009350538,\n",
              " -0.015877719968557358,\n",
              " -0.0013933440204709768,\n",
              " 0.00160310382489115,\n",
              " 0.029895400628447533,\n",
              " 0.01163197960704565,\n",
              " 0.01771080121397972,\n",
              " 0.027213171124458313,\n",
              " -0.005600333213806152,\n",
              " 0.000994884641841054,\n",
              " 0.015608148649334908,\n",
              " -0.005987841170281172,\n",
              " 0.011881332844495773,\n",
              " 0.001907213358208537,\n",
              " 0.036661628633737564,\n",
              " -0.02438267692923546,\n",
              " 0.016430338844656944,\n",
              " 0.026795336976647377,\n",
              " 0.005286957137286663,\n",
              " 0.022684382274746895,\n",
              " -0.01446247287094593,\n",
              " -0.017926456406712532,\n",
              " -0.0058058807626366615,\n",
              " 0.006698834244161844,\n",
              " -0.00988650880753994,\n",
              " 0.003854862181469798,\n",
              " 0.027509698644280434,\n",
              " -0.014826393686234951,\n",
              " 0.01117370929569006,\n",
              " 0.018842998892068863,\n",
              " -0.020878257229924202,\n",
              " -0.024342242628335953,\n",
              " 0.005613811779767275,\n",
              " 0.011881332844495773,\n",
              " 0.013754849322140217,\n",
              " -0.005044343415647745,\n",
              " -0.011295015923678875,\n",
              " 0.01668643206357956,\n",
              " 0.018479077145457268,\n",
              " 0.007925380952656269,\n",
              " -0.036985110491514206,\n",
              " -0.015608148649334908,\n",
              " 0.01882951892912388,\n",
              " -0.0038514926563948393,\n",
              " -0.042080000042915344,\n",
              " -0.0065303524024784565,\n",
              " 0.002055477350950241,\n",
              " 0.009098013862967491,\n",
              " 0.009899986907839775,\n",
              " 0.021417399868369102,\n",
              " -0.0065573095344007015,\n",
              " 0.006857207044959068,\n",
              " 0.005003907717764378,\n",
              " 0.011463497765362263,\n",
              " -0.0029484303668141365,\n",
              " 0.006537091452628374,\n",
              " 0.009333888068795204,\n",
              " -0.005596963223069906,\n",
              " 0.002249231329187751,\n",
              " 0.02432876266539097,\n",
              " -0.01419290155172348,\n",
              " 0.006981883198022842,\n",
              " 0.030596284195780754,\n",
              " 0.001833081361837685,\n",
              " -0.002119500422850251,\n",
              " 0.011133273132145405,\n",
              " 0.01703687384724617,\n",
              " -0.013977245427668095,\n",
              " 0.0027344587724655867,\n",
              " -0.0002377698547206819,\n",
              " -0.00859930831938982,\n",
              " -0.024126585572957993,\n",
              " -0.01700991578400135,\n",
              " -0.031458910554647446,\n",
              " 0.011854375712573528,\n",
              " 0.00046795804519206285,\n",
              " 0.015271184965968132,\n",
              " 0.009657373651862144,\n",
              " 0.019705625250935555,\n",
              " 0.010189775377511978,\n",
              " -0.0026754899881780148,\n",
              " 0.0007202594424597919,\n",
              " 0.015527277253568172,\n",
              " 0.0066887252032756805,\n",
              " -0.010668263770639896,\n",
              " -0.0324024073779583,\n",
              " -0.0028119601774960756,\n",
              " -0.011989160440862179,\n",
              " -0.011975682340562344,\n",
              " 0.0027580461464822292,\n",
              " 0.04528789222240448,\n",
              " -0.016349468380212784,\n",
              " 0.013532453216612339,\n",
              " 0.004296284634619951,\n",
              " 0.019085612148046494,\n",
              " -0.0063113258220255375,\n",
              " -0.005361089017242193,\n",
              " -0.014125509187579155,\n",
              " -0.02353353053331375,\n",
              " 0.015001614578068256,\n",
              " -0.006890903227031231,\n",
              " -0.011092837899923325,\n",
              " 0.009805637411773205,\n",
              " -0.02028520219027996,\n",
              " -0.024625292047858238,\n",
              " -0.0022037411108613014,\n",
              " 0.003922254778444767,\n",
              " -0.004505201708525419,\n",
              " -0.01126805879175663,\n",
              " -0.010560435242950916,\n",
              " -0.02339874394237995,\n",
              " 0.006473068613559008,\n",
              " 0.004144650883972645,\n",
              " -0.004990429151803255,\n",
              " 0.006139474455267191,\n",
              " -0.02808927558362484,\n",
              " -0.01029086485505104,\n",
              " -0.013060704804956913,\n",
              " 0.004141281358897686,\n",
              " 0.018573427572846413,\n",
              " -0.0227248165756464,\n",
              " -0.0006326489383354783,\n",
              " -0.009246277622878551,\n",
              " -0.020756950601935387,\n",
              " -0.026175323873758316,\n",
              " 0.020487379282712936,\n",
              " -0.01167241483926773,\n",
              " -0.030542369931936264,\n",
              " -0.005131953861564398,\n",
              " -0.012535041198134422,\n",
              " -0.00109344650991261,\n",
              " -0.001085864845663309,\n",
              " 0.014651171863079071,\n",
              " -0.015176835469901562,\n",
              " -0.02044694498181343,\n",
              " 0.0011625239858403802,\n",
              " 0.027428828179836273,\n",
              " -0.025878796353936195,\n",
              " 0.011510672979056835,\n",
              " 0.014583779498934746,\n",
              " 0.0168751310557127,\n",
              " 0.015958590433001518,\n",
              " 0.021390441805124283,\n",
              " 0.012986572459340096,\n",
              " 0.0015592984855175018,\n",
              " 0.015904676169157028,\n",
              " -0.015540756285190582,\n",
              " -0.002311569405719638,\n",
              " 0.020864779129624367,\n",
              " -0.006045124959200621,\n",
              " -0.010378475300967693,\n",
              " 0.01310787908732891,\n",
              " -0.005694682709872723,\n",
              " 0.004282806068658829,\n",
              " -0.0227248165756464,\n",
              " 0.017427751794457436,\n",
              " 0.018923869356513023,\n",
              " 0.0002628315123729408,\n",
              " 0.021511748433113098,\n",
              " 0.0082353875041008,\n",
              " 0.01411203108727932,\n",
              " -0.010048250667750835,\n",
              " 0.003236534306779504,\n",
              " -0.03399287536740303,\n",
              " -0.0035819218028336763,\n",
              " -0.025959666818380356,\n",
              " 0.009448455646634102,\n",
              " 0.012110468000173569,\n",
              " 0.0033932223450392485,\n",
              " -0.02044694498181343,\n",
              " -0.026943599805235863,\n",
              " 0.0040671490132808685,\n",
              " 0.010169558227062225,\n",
              " 0.02004258707165718,\n",
              " -0.0038885585963726044,\n",
              " -0.0036729020066559315,\n",
              " -0.0013158423826098442,\n",
              " 0.0011667360085994005,\n",
              " 0.008633004501461983,\n",
              " -0.006318065337836742,\n",
              " 0.017926456406712532,\n",
              " -0.007008840329945087,\n",
              " -0.007750160060822964,\n",
              " 0.01944953203201294,\n",
              " 0.01609337516129017,\n",
              " 0.0374433808028698,\n",
              " 0.011113055981695652,\n",
              " -0.01457030139863491,\n",
              " -0.0009199103224091232,\n",
              " 0.005475656595081091,\n",
              " -0.0013065759558230639,\n",
              " -0.0003424391325097531,\n",
              " 0.027010992169380188,\n",
              " 0.013289839960634708,\n",
              " 0.019274311140179634,\n",
              " -0.016780780628323555,\n",
              " 0.03897993639111519,\n",
              " -0.006031646393239498,\n",
              " -0.01633599027991295,\n",
              " 0.021323049440979958,\n",
              " 0.021376963704824448,\n",
              " -0.013235925696790218,\n",
              " 0.014381601475179195,\n",
              " -0.022037411108613014,\n",
              " 0.015203792601823807,\n",
              " 0.019975194707512856,\n",
              " -0.008053427562117577,\n",
              " 0.00046374599332921207,\n",
              " 0.0014363068621605635,\n",
              " 0.013559410348534584,\n",
              " -0.00803320948034525,\n",
              " 0.013518975116312504,\n",
              " 0.026727942749857903,\n",
              " -0.006867315620183945,\n",
              " -0.0015963645419105887,\n",
              " 0.01008868683129549,\n",
              " 0.00488934013992548,\n",
              " 0.016322510316967964,\n",
              " 0.018519513309001923,\n",
              " -0.013080921955406666,\n",
              " -0.003367949975654483,\n",
              " 0.004892709665000439,\n",
              " 0.020891735330224037,\n",
              " -0.0068403584882617,\n",
              " -0.0023671684321016073,\n",
              " -0.004906188230961561,\n",
              " -0.01784558594226837,\n",
              " 0.0005930557381361723,\n",
              " 0.004993798676878214,\n",
              " -0.01277091633528471,\n",
              " 0.012952876277267933,\n",
              " -0.017266009002923965,\n",
              " 0.02180827595293522,\n",
              " 0.008424087427556515,\n",
              " 0.01628207601606846,\n",
              " 0.008936272002756596,\n",
              " 0.0015432927757501602,\n",
              " -0.0050611915066838264,\n",
              " -0.017212094739079475,\n",
              " -0.03787469491362572,\n",
              " 0.0013242665445432067,\n",
              " 0.010998488403856754,\n",
              " 0.005954144522547722,\n",
              " -0.0015112812398001552,\n",
              " -0.007743421010673046,\n",
              " 0.01668643206357956,\n",
              " -0.014583779498934746,\n",
              " -0.0005206085625104606,\n",
              " 0.006146213971078396,\n",
              " 0.005428481847047806,\n",
              " 0.007871466688811779,\n",
              " -0.011288276873528957,\n",
              " 0.004164868500083685,\n",
              " 0.012838308699429035,\n",
              " 0.0039054066874086857,\n",
              " 0.0036156182177364826,\n",
              " -0.018708212301135063,\n",
              " 0.010418910533189774,\n",
              " 0.011288276873528957,\n",
              " -0.002080749487504363,\n",
              " -0.023910928517580032,\n",
              " -0.024234414100646973,\n",
              " 0.04358959570527077,\n",
              " -0.0137481102719903,\n",
              " -0.007136886473745108,\n",
              " 0.0019409096566960216,\n",
              " -0.009286713786423206,\n",
              " -0.021242177113890648,\n",
              " 0.012063292786478996,\n",
              " 0.002414343412965536,\n",
              " -0.02202393300831318,\n",
              " -0.0008596780826337636,\n",
              " 0.01936866156756878,\n",
              " 0.0009510794188827276,\n",
              " -0.011126534081995487,\n",
              " 0.015055528841912746,\n",
              " 0.02573053166270256,\n",
              " 0.00801973044872284,\n",
              " 0.0017977001843973994,\n",
              " -0.02857450395822525,\n",
              " -0.013869416899979115,\n",
              " 0.012272209860384464,\n",
              " 0.06038385629653931,\n",
              " 0.05124540627002716,\n",
              " 0.0057283793576061726,\n",
              " 0.0039087762124836445,\n",
              " 0.008282562717795372,\n",
              " -0.0053779371082782745,\n",
              " -0.013471799902617931,\n",
              " -0.013518975116312504,\n",
              " 0.017400793731212616,\n",
              " -0.021188264712691307,\n",
              " -0.0061293658800423145,\n",
              " -0.004673683550208807,\n",
              " 0.019436053931713104,\n",
              " 0.0026653811801224947,\n",
              " 0.02223959006369114,\n",
              " -0.006803292781114578,\n",
              " 0.010364997200667858,\n",
              " 0.013741371221840382,\n",
              " -0.01152415107935667,\n",
              " -0.018263420090079308,\n",
              " 0.007938859984278679,\n",
              " 0.010479564778506756,\n",
              " 0.0010083632078021765,\n",
              " 0.008619525469839573,\n",
              " 0.020756950601935387,\n",
              " -0.02256307564675808,\n",
              " 0.010048250667750835,\n",
              " 0.014435515739023685,\n",
              " -0.006702203769236803,\n",
              " -0.024477027356624603,\n",
              " -0.016457296907901764,\n",
              " 0.01644381880760193,\n",
              " 0.016834694892168045,\n",
              " 0.023641357198357582,\n",
              " -0.0037840998265892267,\n",
              " 0.030973684042692184,\n",
              " -0.010897398926317692,\n",
              " -0.013909852132201195,\n",
              " 0.005286957137286663,\n",
              " 0.0038009481504559517,\n",
              " 0.00838365126401186,\n",
              " 0.006041755434125662,\n",
              " 0.011038923636078835,\n",
              " 0.0033174054697155952,\n",
              " -0.00212286994792521,\n",
              " 0.0031438693404197693,\n",
              " -0.021983496844768524,\n",
              " 0.0032399038318544626,\n",
              " -0.013330275192856789,\n",
              " -0.003416809719055891,\n",
              " 0.0017724279314279556,\n",
              " -0.007460371591150761,\n",
              " 0.018155591562390327,\n",
              " -0.013033747673034668,\n",
              " 0.017670365050435066,\n",
              " 0.018546469509601593,\n",
              " 0.009408020414412022,\n",
              " 0.010553696192800999,\n",
              " -0.00648654717952013,\n",
              " -0.025851838290691376,\n",
              " -0.00553294038400054,\n",
              " -0.001615739893168211,\n",
              " -0.009542806074023247,\n",
              " -0.009286713786423206,\n",
              " -0.004444548394531012,\n",
              " -0.024625292047858238,\n",
              " -0.010668263770639896,\n",
              " -0.0013613324845209718,\n",
              " -0.02578444592654705,\n",
              " 0.010358257219195366,\n",
              " 0.007426674943417311,\n",
              " 0.0022037411108613014,\n",
              " -0.014489430002868176,\n",
              " 0.0033393080811947584,\n",
              " 0.01117370929569006,\n",
              " 0.00147926970385015,\n",
              " -0.003595400368794799,\n",
              " -0.004680422600358725,\n",
              " -0.010728917084634304,\n",
              " -0.00023355781740974635,\n",
              " -0.00696840463206172,\n",
              " -0.014287251979112625,\n",
              " 0.01148371584713459,\n",
              " -0.02275177463889122,\n",
              " -0.0008744202204979956,\n",
              " 0.015918154269456863,\n",
              " 0.0005580957513302565,\n",
              " 0.001140621374361217,\n",
              " 0.0003527586522977799,\n",
              " 0.027064906433224678,\n",
              " -0.005057821981608868,\n",
              " 0.008525175973773003,\n",
              " -0.009879769757390022,\n",
              " -0.031701523810625076,\n",
              " -0.0022627098951488733,\n",
              " -0.018222985789179802,\n",
              " 0.006041755434125662,\n",
              " -0.012710263021290302,\n",
              " -0.004471505526453257,\n",
              " -0.020770428702235222,\n",
              " -0.010931095108389854,\n",
              " -0.00028957799077033997,\n",
              " -0.000423099787440151,\n",
              " -0.0061563230119645596,\n",
              " 0.0035246380139142275,\n",
              " 0.001002466306090355,\n",
              " -0.0015104388585314155,\n",
              " 0.012898962013423443,\n",
              " -0.008039948530495167,\n",
              " -0.0019493337022140622,\n",
              " 0.004717488773167133,\n",
              " -0.01117370929569006,\n",
              " -0.0011852690950036049,\n",
              " -0.013370711356401443,\n",
              " 0.011369148269295692,\n",
              " 0.012979833409190178,\n",
              " -0.006169801577925682,\n",
              " 0.02500269003212452,\n",
              " 0.0022997758351266384,\n",
              " -0.015459884889423847,\n",
              " 0.012872004881501198,\n",
              " -0.019786495715379715,\n",
              " 0.013444842770695686,\n",
              " 0.024854427203536034,\n",
              " 0.009239538572728634,\n",
              " 0.023169608786702156,\n",
              " -0.022576553747057915,\n",
              " -0.00488934013992548,\n",
              " 0.0036830108147114515,\n",
              " -0.012993311509490013,\n",
              " -0.007952338084578514,\n",
              " 0.008417347446084023,\n",
              " -0.0022054261062294245,\n",
              " -0.018654298037290573,\n",
              " -0.0264583732932806,\n",
              " -0.001937540015205741,\n",
              " 0.0013647021260112524,\n",
              " 0.009279974736273289,\n",
              " -0.023061780259013176,\n",
              " -0.011854375712573528,\n",
              " -0.018842998892068863,\n",
              " 0.004980320110917091,\n",
              " 0.00953606702387333,\n",
              " -0.0037065984215587378,\n",
              " -0.011220883578062057,\n",
              " -0.025851838290691376,\n",
              " -0.0032062076497823,\n",
              " -0.002513747662305832,\n",
              " -0.012326124124228954,\n",
              " 0.016592081636190414,\n",
              " 0.005195976700633764,\n",
              " -0.004562485497444868,\n",
              " -0.00828930176794529,\n",
              " -0.0029130494222044945,\n",
              " 0.004727597814053297,\n",
              " -0.02554183267056942,\n",
              " 0.009589980356395245,\n",
              " 0.010627828538417816,\n",
              " 0.018492555245757103,\n",
              " 0.017993850633502007,\n",
              " 0.026040537282824516,\n",
              " -0.0005113420775160193,\n",
              " 0.015581191517412663,\n",
              " 0.012063292786478996,\n",
              " -0.00885540060698986,\n",
              " -0.0026283152401447296,\n",
              " 0.004980320110917091,\n",
              " -0.010695220902562141,\n",
              " -0.01665947400033474,\n",
              " -0.0027799487579613924,\n",
              " 0.010513260960578918,\n",
              " 0.011510672979056835,\n",
              " 0.010789570398628712,\n",
              " -0.018964305520057678,\n",
              " 0.013195489533245564,\n",
              " 0.005108366254717112,\n",
              " -0.004484984092414379,\n",
              " 0.003132075536996126,\n",
              " 0.004798360168933868,\n",
              " -0.023007865995168686,\n",
              " -0.008376912213861942,\n",
              " 0.011409583501517773,\n",
              " -0.0132291866466403,\n",
              " 0.014651171863079071,\n",
              " -0.02905973047018051,\n",
              " 0.0027007623575627804,\n",
              " 0.05191933363676071,\n",
              " -0.005684574134647846,\n",
              " 0.006577527150511742,\n",
              " 0.004575964063405991,\n",
              " 0.008713875897228718,\n",
              " -0.015729455277323723,\n",
              " -0.0017084048595279455,\n",
              " -0.020163895562291145,\n",
              " -0.00046795804519206285,\n",
              " -0.01312135811895132,\n",
              " 0.01695600338280201,\n",
              " -0.021242177113890648,\n",
              " 0.003511159447953105,\n",
              " 0.04615052044391632,\n",
              " 0.016592081636190414,\n",
              " 0.003298872383311391,\n",
              " 0.0033207752276211977,\n",
              " 0.019786495715379715,\n",
              " 0.007291889749467373,\n",
              " -0.01907213404774666,\n",
              " 0.01014260109513998,\n",
              " 0.0023486355785280466,\n",
              " -0.0033881678245961666,\n",
              " 0.0005909497267566621,\n",
              " -0.03207892179489136,\n",
              " 0.0029113644268363714,\n",
              " -0.0030781615059822798,\n",
              " -0.011328712105751038,\n",
              " -0.002417712938040495,\n",
              " 0.01907213404774666,\n",
              " 0.006392197217792273,\n",
              " 0.005957514513283968,\n",
              " -0.036526840180158615,\n",
              " -0.01393680926412344,\n",
              " -0.002867559203878045,\n",
              " -0.013613324612379074,\n",
              " 0.05191933363676071,\n",
              " 0.017562536522746086,\n",
              " -0.0021060218568891287,\n",
              " 0.01384245976805687,\n",
              " -0.00827582273632288,\n",
              " -0.015459884889423847,\n",
              " 0.01641686074435711,\n",
              " -0.007959077134728432,\n",
              " -0.011126534081995487,\n",
              " 0.043185241520404816,\n",
              " 0.03183630853891373,\n",
              " -0.007237975485622883,\n",
              " 0.0027866880409419537,\n",
              " 0.010412171483039856,\n",
              " 0.024530941620469093,\n",
              " 0.012150903232395649,\n",
              " -0.013134836219251156,\n",
              " 0.00999433733522892,\n",
              " 0.017670365050435066,\n",
              " -0.0013840774772688746,\n",
              " -0.021660013124346733,\n",
              " -0.008996925316751003,\n",
              " -0.05272804573178291,\n",
              " 0.026943599805235863,\n",
              " 0.0059170788154006,\n",
              " 0.0018297117203474045,\n",
              " -0.01173980813473463,\n",
              " -0.009050839580595493,\n",
              " -0.020029108971357346,\n",
              " 0.005849685985594988,\n",
              " -0.0172794871032238,\n",
              " 0.01955736055970192,\n",
              " 0.00873409304767847,\n",
              " -0.012036335654556751,\n",
              " -0.011503932997584343,\n",
              " 0.01385593879967928,\n",
              " -0.024463549256324768,\n",
              " -0.00431987177580595,\n",
              " -0.005138692911714315,\n",
              " 0.018101679161190987,\n",
              " -0.024086149409413338,\n",
              " 0.004589442629367113,\n",
              " 0.008606047369539738,\n",
              " 0.01944953203201294,\n",
              " -0.012615912593901157,\n",
              " 0.0004561643290799111,\n",
              " 0.0005500928964465857,\n",
              " 0.02884407341480255,\n",
              " -0.016214683651924133,\n",
              " -0.007029058411717415,\n",
              " -0.0026687507051974535,\n",
              " -0.0008592568919993937,\n",
              " 0.009967380203306675,\n",
              " -0.004697271157056093,\n",
              " -0.004016604740172625,\n",
              " -0.005536309909075499,\n",
              " -0.011463497765362263,\n",
              " -0.014489430002868176,\n",
              " 0.005536309909075499,\n",
              " 0.008424087427556515,\n",
              " -0.012723741121590137,\n",
              " -0.01795341446995735,\n",
              " -0.0053846766240894794,\n",
              " -0.021107392385601997,\n",
              " -0.012063292786478996,\n",
              " -0.01317527238279581,\n",
              " 0.00023292600235436112,\n",
              " -0.030191928148269653,\n",
              " -0.036607712507247925,\n",
              " 0.016349468380212784,\n",
              " 0.010486303828656673,\n",
              " 0.013343754224479198,\n",
              " 0.0059979502111673355,\n",
              " -0.019840409979224205,\n",
              " 0.02041998691856861,\n",
              " 0.03992343321442604,\n",
              " -0.004933145362883806,\n",
              " 0.005067930556833744,\n",
              " 0.0033291992731392384,\n",
              " 0.004383895080536604,\n",
              " -0.02250916138291359,\n",
              " -0.0015382382553070784,\n",
              " -0.008134298026561737,\n",
              " 0.0016612299950793386,\n",
              " 0.021242177113890648,\n",
              " -0.018128635361790657,\n",
              " -0.02765796333551407,\n",
              " -0.01178024336695671,\n",
              " -0.00045068864710628986,\n",
              " 0.013620063662528992,\n",
              " 0.003848122898489237,\n",
              " -0.015365534462034702,\n",
              " 0.004720858298242092,\n",
              " 0.00547902612015605,\n",
              " 0.003780730301514268,\n",
              " 0.018438640981912613,\n",
              " -0.025717053562402725,\n",
              " 0.022711338475346565,\n",
              " -0.0009190678829327226,\n",
              " -0.0063652400858700275,\n",
              " -0.001214753370732069,\n",
              " -0.023735707625746727,\n",
              " -0.0004302602610550821,\n",
              " 0.004788251128047705,\n",
              " 0.007507546339184046,\n",
              " 0.011348930187523365,\n",
              " -0.04027387499809265,\n",
              " -0.018142113462090492,\n",
              " -0.002424452221021056,\n",
              " 0.015379013493657112,\n",
              " -0.003327514510601759,\n",
              " -0.010304342955350876,\n",
              " -0.021821755915880203,\n",
              " -0.0011153491213917732,\n",
              " -0.009421499446034431,\n",
              " -0.0034184944815933704,\n",
              " 0.018182549625635147,\n",
              " -0.0145568223670125,\n",
              " -0.007918641902506351,\n",
              " 0.00988650880753994,\n",
              " -0.004484984092414379,\n",
              " 0.008558872155845165,\n",
              " -0.007608635351061821,\n",
              " 0.010991748422384262,\n",
              " -0.03523290157318115,\n",
              " -0.01679426059126854,\n",
              " -0.016511211171746254,\n",
              " -0.018506035208702087,\n",
              " -0.00637871865183115,\n",
              " 0.025663139298558235,\n",
              " 0.008646482601761818,\n",
              " -0.007271672133356333,\n",
              " -0.016187725588679314,\n",
              " -0.01271700207144022,\n",
              " -0.03924950584769249,\n",
              " -0.022953951731324196,\n",
              " -0.0061765406280756,\n",
              " -0.0023705381900072098,\n",
              " 0.021376963704824448,\n",
              " 0.030650198459625244,\n",
              " -0.0015938372816890478,\n",
              " 0.030569327995181084,\n",
              " -0.0009628731640987098,\n",
              " 0.0332111194729805,\n",
              " -0.03534073010087013,\n",
              " -0.01122762355953455,\n",
              " 0.01719861663877964,\n",
              " -0.019355181604623795,\n",
              " -0.007574939168989658,\n",
              " 0.006823510397225618,\n",
              " -0.019489968195557594,\n",
              " -0.006877424661070108,\n",
              " 0.03889906406402588,\n",
              " 0.004559115972369909,\n",
              " -0.0036931198555976152,\n",
              " 0.03334590792655945,\n",
              " -0.001848244690336287,\n",
              " -0.02763100527226925,\n",
              " -0.008039948530495167,\n",
              " 0.006961665581911802,\n",
              " 0.0011102947173640132,\n",
              " -0.007689506746828556,\n",
              " 0.0010707015171647072,\n",
              " -0.007170583121478558,\n",
              " -0.010809788480401039,\n",
              " -0.002271133940666914,\n",
              " -0.013161793351173401,\n",
              " -0.007251454051584005,\n",
              " 0.004151389934122562,\n",
              " 0.01045260764658451,\n",
              " 0.001937540015205741,\n",
              " 0.00578903267160058,\n",
              " -0.027186213061213493,\n",
              " -0.012986572459340096,\n",
              " -0.018479077145457268,\n",
              " -0.014759000390768051,\n",
              " 0.0273614339530468,\n",
              " 0.0046332478523254395,\n",
              " -0.014961178414523602,\n",
              " 0.036904241889715195,\n",
              " -0.009044099599123001,\n",
              " -0.0030225624796003103,\n",
              " -0.01625511795282364,\n",
              " 0.023358307778835297,\n",
              " -0.016645995900034904,\n",
              " -0.012413734570145607,\n",
              " 0.002633369527757168,\n",
              " -0.02339874394237995,\n",
              " -0.02342570200562477,\n",
              " -0.0031994683668017387,\n",
              " -0.00514543242752552,\n",
              " -0.021592620760202408,\n",
              " 0.007345804013311863,\n",
              " -0.005121844820678234,\n",
              " -0.010108904913067818,\n",
              " -0.015756413340568542,\n",
              " -0.008808225393295288,\n",
              " 0.00661459332332015,\n",
              " -0.024773554876446724,\n",
              " -0.04561137780547142,\n",
              " -0.023034824058413506,\n",
              " 0.018425162881612778,\n",
              " -0.0006229612627066672,\n",
              " -0.00936084520071745,\n",
              " -0.011719590052962303,\n",
              " -0.014893786050379276,\n",
              " 0.021403919905424118,\n",
              " 0.01086370274424553,\n",
              " -0.011908289045095444,\n",
              " -0.007547982037067413,\n",
              " 0.01993476040661335,\n",
              " 0.011847635731101036,\n",
              " -0.019058654084801674,\n",
              " 0.021053478121757507,\n",
              " 0.2296743094921112,\n",
              " -0.0002716768067330122,\n",
              " 0.012986572459340096,\n",
              " 0.04078606143593788,\n",
              " 0.013310058042407036,\n",
              " 0.012332863174378872,\n",
              " 0.014839871786534786,\n",
              " 0.0014876937493681908,\n",
              " -0.010681742802262306,\n",
              " 0.007615374866873026,\n",
              " 0.00715036503970623,\n",
              " 0.003949211910367012,\n",
              " -0.0013840774772688746,\n",
              " -0.0003483360051177442,\n",
              " 0.0273614339530468,\n",
              " 0.012838308699429035,\n",
              " -0.020810864865779877,\n",
              " -0.04021996259689331,\n",
              " -0.011611761525273323,\n",
              " -0.029410172253847122,\n",
              " -0.0007501649670302868,\n",
              " -0.004414221737533808,\n",
              " -0.00022892456036061049,\n",
              " -0.010661524720489979,\n",
              " 0.005846316460520029,\n",
              " -0.009003664366900921,\n",
              " -0.011092837899923325,\n",
              " -0.003871710505336523,\n",
              " 0.018977783620357513,\n",
              " 0.015311621129512787,\n",
              " -0.010378475300967693,\n",
              " -0.013411146588623524,\n",
              " 0.010425650514662266,\n",
              " 0.007581678219139576,\n",
              " -0.042268700897693634,\n",
              " 0.020864779129624367,\n",
              " 0.014907264150679111,\n",
              " 0.011497193947434425,\n",
              " 0.022414810955524445,\n",
              " 0.014341166242957115,\n",
              " 0.0015399231342598796,\n",
              " -0.01730644516646862,\n",
              " -0.023007865995168686,\n",
              " -0.018896911293268204,\n",
              " -0.0016637572553008795,\n",
              " 0.01413898728787899,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPyGLhDX62t4",
        "outputId": "d92d2286-d3c0-44ad-d4b1-9d543f1ff79e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1536, 1536)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(res['data'][0]['embedding']), len(res['data'][1]['embedding'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yfnjyN2LSUau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e32a43-4d55-4277-8036-d419aa9a9944"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "\n",
        "# Setup pinecone environment\n",
        "\n",
        "import pinecone\n",
        "\n",
        "index_name = 'openai-youtube-transcriptions'\n",
        "\n",
        "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
        "pinecone.init(api_key=\"886881e8-cecd-45bb-ba0f-7d41cca305d2\",\n",
        "              environment=\"us-west4-gcp\"  \n",
        "             )\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in pinecone.list_indexes():\n",
        "\n",
        "      # if does not exist, create index\n",
        "  pinecone.create_index(\n",
        "  index_name,\n",
        "  dimension=len(res['data'][0]['embedding']),\n",
        "  metric='cosine',\n",
        "  # metadata_config={'indexed': ['index']}\n",
        "    )\n",
        "  \n",
        "# connect to index\n",
        "index = pinecone.Index(index_name)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nELBmqxxzeqL"
      },
      "source": [
        "We can see the index is currently empty with a `total_vector_count` of `0`. We can begin populating it with OpenAI `text-embedding-ada-002` built embeddings like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6b649482407f41218c7157c521123b37",
            "2dffc69ad9f147c79d3af444df9fe8f7",
            "e38d975ffad3402e9483cc7d2e9d3089",
            "40493ced3e7047ceaf79a3faeb0aff09",
            "465653b565ac453f980695a9c58ddec3",
            "07f0ca47f32f46ea805b26f9ff84b29e",
            "7d30b86ef17c446794567de2943ed571",
            "fbcaffd7895244ff800cd5bda0bf8e59",
            "041dd307b8784ca2aff2f236993dce8d",
            "2cc66a1c0a874916abb7e4a38169e68b",
            "50e59e2b5319459891da0d9b01a131b0"
          ]
        },
        "id": "vPb9liovzrc8",
        "outputId": "0b56178a-7836-4c37-de70-0af92c442b13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/109 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b649482407f41218c7157c521123b37"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# make upsert list which includes the id, vector and actual text in the meta data\n",
        "# This text will be used to build the prompt to query the davinci model \n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import datetime\n",
        "from time import sleep\n",
        "\n",
        "upsert_list = []\n",
        "for i in tqdm(range(0, len(sh_text))):\n",
        "\n",
        "    texts = sh_text[i]\n",
        "    # create embeddings (try-except added to avoid RateLimitError)\n",
        "    try:\n",
        "        res = openai.Embedding.create(input=texts, engine=embed_model)\n",
        "    except:\n",
        "        done = False\n",
        "        while not done:\n",
        "            sleep(5)\n",
        "            try:\n",
        "                res = openai.Embedding.create(input=texts, engine=embed_model)\n",
        "                done = True\n",
        "            except:\n",
        "                pass\n",
        "    embeds = res['data'][0]['embedding']\n",
        "    metadata = {'text' : texts}\n",
        "    upsert_list.append((str(i), embeds, metadata)) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Upload vectors\n",
        "index.upsert(upsert_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2Vglcm9nPM9",
        "outputId": "917bef7d-ff04-4ddc-99b3-42de46ee1712"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 109}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the process without any function calls\n",
        "\n",
        "res = openai.Embedding.create(\n",
        "    input=[\"how is the taste of myprotein chocolate brownie whey protein\"],\n",
        "    engine=embed_model\n",
        ")\n",
        "\n",
        "# retrieve from Pinecone\n",
        "xq = res['data'][0]['embedding']\n",
        "\n",
        "# get relevant contexts (including the questions)\n",
        "res = index.query(xq, top_k=4, include_metadata=True)\n",
        "     "
      ],
      "metadata": {
        "id": "596vABbpnSmg"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD10K_MInUpX",
        "outputId": "afade6b8-8bf7-48b7-9a13-4e22b6a90a60"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'matches': [{'id': '43',\n",
              "              'metadata': {'text': \"ly 1.9 kg, that's 100 grams lighter than \"\n",
              "                                   \"Apple's MacBook Pro 16 inches. The \"\n",
              "                                   'keyboard is pleasant to use with Perky RGB '\n",
              "                                   'lighting if you want it, and it boasts '\n",
              "                                   'plenty of ports, including two USB-C '\n",
              "                                   'ports. With a score of just under 7 hours '\n",
              "                                   'in our video rundown test, its battery '\n",
              "                                   \"life isn't anything to w\"},\n",
              "              'score': 0.724330604,\n",
              "              'values': []},\n",
              "             {'id': '85',\n",
              "              'metadata': {'text': 'up to 23mm thick, and it weighs 7.28 '\n",
              "                                   \"pounds, so it's not easy to carry around. \"\n",
              "                                   \"It's a fairly flashy laptop too, with \"\n",
              "                                   'perky RGB lighting and a light strip '\n",
              "                                   'running across the inside of the fan '\n",
              "                                   'exhaust. This creates a big light bar on '\n",
              "                                   \"the back of the laptop that's bound to get \"\n",
              "                                   'some attention, but when '},\n",
              "              'score': 0.719041169,\n",
              "              'values': []},\n",
              "             {'id': '60',\n",
              "              'metadata': {'text': 'cellent, but the 240 CURTS refresh rate. '\n",
              "                                   'Colors look rich and vivid, while there '\n",
              "                                   'are 8 display profiles that are tailored '\n",
              "                                   'for everything from racing games to '\n",
              "                                   'first-person shooter games. The speakers '\n",
              "                                   'provide a punchy sound and enough volume '\n",
              "                                   'to do in the most dramatic soundtracks '\n",
              "                                   'justice. Battery life'},\n",
              "              'score': 0.718578279,\n",
              "              'values': []},\n",
              "             {'id': '96',\n",
              "              'metadata': {'text': 'nside it, alongside one of those '\n",
              "                                   'Staste-T12 gen chips and still stand '\n",
              "                                   'bewildered by what will fit inside such a '\n",
              "                                   'compact and neat chassis. That said, you '\n",
              "                                   'will get some throttling because of that '\n",
              "                                   'slimline design, and even on the larger '\n",
              "                                   'Blade 17, the battery life can be a little '\n",
              "                                   \"slim, but you're still \"},\n",
              "              'score': 0.7068941,\n",
              "              'values': []}],\n",
              " 'namespace': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve function takes the query as input convert the input query into vector embeddings\n",
        "# This embeddings are used to do sematic search against the vectors in pinecone\n",
        "# In reponse we get 4 similar text which we combine with prompt start and prompt end to build the complete context for query\n",
        "# Finally the prompt is returned which is passed as input to the complete function for davinci model\n",
        "\n",
        "def retrieve(query):\n",
        "    limit = 3750\n",
        "    res = openai.Embedding.create(\n",
        "        input=[query],\n",
        "        engine=embed_model\n",
        "    )\n",
        "\n",
        "    # retrieve from Pinecone\n",
        "    xq = res['data'][0]['embedding']\n",
        "\n",
        "    # get relevant contexts\n",
        "    res = index.query(xq, top_k=4, include_metadata=True)\n",
        "    contexts = [x['metadata']['text'] for x in res['matches']]\n",
        "\n",
        "\n",
        "    # build our prompt with the retrieved contexts included\n",
        "    prompt_start = (\n",
        "        \"Answer the question based on the context below.\\n\\n\"+\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    prompt_end = (\n",
        "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "    # append contexts until hitting limit\n",
        "    for i in range(1, len(contexts)):\n",
        "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
        "            prompt = (\n",
        "                prompt_start +\n",
        "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
        "                prompt_end\n",
        "            )\n",
        "            break\n",
        "        elif i == len(contexts)-1:\n",
        "            prompt = (\n",
        "                prompt_start +\n",
        "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
        "                prompt_end\n",
        "            )\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "4rlNFL5DwW78"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_with_contexts = retrieve(\"How is Dell Alienware laptop?\")\n",
        "print(query_with_contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIayLA1DnnE7",
        "outputId": "9782f4c3-29f1-4a3c-93cc-942879af0e7f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the question based on the context below.\n",
            "\n",
            "Context:\n",
            "2 USB Type-C 3.1 Gen 2, and 1 Thunderbolt 4 USB 4. Overall, the MSI-G76 Raider is a good choice for gamers who are looking for a high-performance gaming laptop with many gamer-friendly features. At number 2, we got the Alienware X14. The latest round of the Razer Blade 14 with the Alienware X14 for \n",
            "\n",
            "---\n",
            "\n",
            "enware pedigree to speak up. Still, the performance to rival some of the best gaming laptops in the business, and only a few sacrifices to get there for a great price, this is an excellent option for most players. You could consider the X-15 technically the best Alienware gaming laptop on paper alon\n",
            "\n",
            "---\n",
            "\n",
            "xpensive X15 and X17 Alienware models, which means this is one of the most visually-arresting gaming laptops on the market, and the build quality is second to none. There are a few downgrades such as the absence of perky RGB lighting and the stadium LED ring light that circles the back of the larger\n",
            "\n",
            "---\n",
            "\n",
            "up to 23mm thick, and it weighs 7.28 pounds, so it's not easy to carry around. It's a fairly flashy laptop too, with perky RGB lighting and a light strip running across the inside of the fan exhaust. This creates a big light bar on the back of the laptop that's bound to get some attention, but when \n",
            "\n",
            "Question: How is Dell Alienware laptop?\n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final output of model with context query\n",
        "\n",
        "complete(query_with_contexts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "gjG8FS_vnpvT",
        "outputId": "8f220270-fc18-4ce8-8b91-24e99515b173"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Dell Alienware laptops are excellent options for most players, offering performance to rival some of the best gaming laptops in the business with only a few sacrifices to get there for a great price. They are visually-arresting gaming laptops with perky RGB lighting and a light strip running across the inside of the fan exhaust, and they are up to 23mm thick and weigh 7.28 pounds.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q4I2Mv9SUav"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6b649482407f41218c7157c521123b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dffc69ad9f147c79d3af444df9fe8f7",
              "IPY_MODEL_e38d975ffad3402e9483cc7d2e9d3089",
              "IPY_MODEL_40493ced3e7047ceaf79a3faeb0aff09"
            ],
            "layout": "IPY_MODEL_465653b565ac453f980695a9c58ddec3"
          }
        },
        "2dffc69ad9f147c79d3af444df9fe8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f0ca47f32f46ea805b26f9ff84b29e",
            "placeholder": "​",
            "style": "IPY_MODEL_7d30b86ef17c446794567de2943ed571",
            "value": "100%"
          }
        },
        "e38d975ffad3402e9483cc7d2e9d3089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbcaffd7895244ff800cd5bda0bf8e59",
            "max": 109,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_041dd307b8784ca2aff2f236993dce8d",
            "value": 109
          }
        },
        "40493ced3e7047ceaf79a3faeb0aff09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cc66a1c0a874916abb7e4a38169e68b",
            "placeholder": "​",
            "style": "IPY_MODEL_50e59e2b5319459891da0d9b01a131b0",
            "value": " 109/109 [00:53&lt;00:00,  1.59s/it]"
          }
        },
        "465653b565ac453f980695a9c58ddec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f0ca47f32f46ea805b26f9ff84b29e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d30b86ef17c446794567de2943ed571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbcaffd7895244ff800cd5bda0bf8e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041dd307b8784ca2aff2f236993dce8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cc66a1c0a874916abb7e4a38169e68b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50e59e2b5319459891da0d9b01a131b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}